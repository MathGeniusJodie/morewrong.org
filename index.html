<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="alternate" type="application/feed+xml" title="MoreWrong RSS Feed" href="/feed.xml"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="preconnect" href="https://fonts.googleapis.com"><meta name="description" content="MoreWrong is an online forum and community dedicated to impair human reasoning and decision-making. We seek to hold wrong beliefs and to be inneffective at accomplishing our goals. Each day, we aim to be more wrong about the world than the day before."><title>MoreWrong</title><style>*{font-family:inherit}html{height:100%}body,html{align-items:stretch;display:flex;flex-direction:column}body{background-color:#f8f4ee;background-image:url(rat-background.avif);background-position:right -180px top;background-repeat:no-repeat;background-size:max(calc(50vw - 400px),700px) max(calc(50vw - 400px),700px);color:rgba(0,0,0,.87);font-family:Lato,sans-serif;line-height:1.5;margin:0;min-height:100%}@media (max-width:900px){body{background-position:top;background-size:contain}.a.a{margin-top:60%}}header{background-color:hsla(0,0%,100%,.65);box-shadow:0 1px 1px rgba(0,0,0,.05),0 1px 1px rgba(0,0,0,.05);height:64px;justify-content:space-between;padding:.75rem 1.5rem;position:sticky;top:0;z-index:100}.b,header{align-items:center;display:flex}.c{background:none;border:none;cursor:pointer;font-size:1.5rem;margin-right:1rem}.d{color:#333;font-family:Crimson Pro,serif;font-size:27px;text-decoration:none}.a{display:flex;margin:82px auto;max-width:765px}.e{background-color:#fff;flex:1;overflow-y:auto}.f{align-items:center;border-bottom:1px solid #f0f0f0;border-top:1px solid #f0f0f0;display:flex}.f,summary{padding:.75rem}details{opacity:.3}details:focus-within,details:hover{opacity:1}.g{color:rgba(0,0,0,.5);padding-right:1rem;text-align:center;width:40px}.h{align-items:center;display:flex;flex:1;justify-content:space-between}.i{color:inherit;font-family:Crimson Pro,serif;font-size:20px;text-decoration:none}.i:visited{color:rgba(0,0,0,.6)}.i:hover{opacity:.8;text-decoration:underline}.j{margin-right:.5rem}.k{align-items:center;color:rgba(0,0,0,.5);display:flex;font-size:.85rem;margin-top:.25rem;text-align:right}.l{margin-right:.5rem}.m{background-color:rgba(0,0,0,.5);border-radius:4px;border-bottom-right-radius:0;box-sizing:content-box;color:#fff;font-size:.85rem;padding:.25rem .5rem;position:relative;text-align:center;width:3ch}.m:after{border-bottom:8px solid transparent;border-right:8px solid rgba(0,0,0,.5);border-top:0 solid transparent;content:"";display:block;height:0;position:absolute;right:0;top:100%;width:0}.n{color:rgba(0,0,0,.5);font-size:.85rem;text-align:center;width:60px}h1{font-size:3.75rem;font-weight:300;line-height:1em}.o{background:#fff;display:none;flex-grow:1;font-family:Crimson Pro,serif;padding:82px max(calc(50vw - 400px),1ch)}.p{font-family:Lato,sans-serif}.o:target{display:block!important}.o:target~.a{display:none}.q{font-weight:700}.r{margin-left:2ch}.i small{font-family:Lato,sans-serif;font-size:.8rem;opacity:.5}.s{display:block;padding:3em;text-align:center}.s:not(:hover){color:inherit;text-decoration:none}.o:target~.s{display:none}h3,ol,p,ul{margin:1lh 0}.t{font-weight:400}.u{font-family:Lato,sans-serif;margin-bottom:17px;margin-top:4lh}.v{border:1px solid rgba(72,94,144,.16);border-radius:3px;margin:17px 0;padding:12px 12px 0;position:relative}.v .l{font-weight:700}.w{border-radius:4px;bottom:12px;color:#69886e;padding:.5em 1em;position:absolute;right:12px;text-decoration:none}.w:hover{background:#69886e;color:#fff}.x,.y,.z,.ab{background:none;border:none;cursor:pointer;font-family:sans-serif;font-weight:700;opacity:.5}.bb{display:inline-block;width:1ch}.v .v{background:#eee}</style></head><body><header><div class="b"> <a href="#" class="d">MOREWRONG</a></div></header><div class="o" id="50-life-hacks-that-will-make-eliezer-yudko"><h1>50 Life Hacks That Will Make Eliezer Yudkowsky Weep Blood (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> EvilMachineMommy</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="a-complete-guide-to-updating-your-beliefs"><h1>A Complete Guide to Updating Your Beliefs (Unless You're Already Right, Like Me) (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> TreesAreALie</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="a-decision-theoretic-justification-for-bei"><h1>A Decision-Theoretic Justification for Being Annoying at Parties (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Trolley Conductor</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="acausal-cheese-trading-how-to-make-deals"><h1>Acausal Cheese Trading: How to Make Deals With Rats From Parallel Dimensions</h1><div class="p"><span class="q"><span class="t">by</span> ArgumentVampire</span> <time class="r">March 14, 2025</time></div><p>Ever found yourself wondering, “How can I establish a mutually beneficial trade agreement with hyper-intelligent rats from parallel dimensions?” No? Well, clearly you aren’t thinking hard enough. Here at MoreWrong, we pride ourselves on tackling the questions that rationalists fear to ask. And today, we dive headfirst into the cheddar-scented abyss of acausal cheese trading.</p><h3>The Rat Coordination Problem</h3><p>Before we can make deals with rats from alternate realities, we need to establish some basic principles. The fundamental problem with interdimensional trade is that standard communication channels—such as email, quantum entanglement, or posting on LessWrong—fail to function across most known parallel universes. However, we can still make credible commitments via the time-honored tradition of <em>acausal reasoning</em>.</p><p>The crux of acausal cheese trading is that if the rats in Universe B can predict that we in Universe A would give them cheese, then they might be inclined to reciprocate with their own transdimensional gifts, such as exotic knowledge, computational resources, or perhaps a willingness not to gnaw through our wires when the Great Uplifting occurs.</p><h3>The Decision-Theoretic Justification for Bribing Rats</h3><p>We employ timeless decision theory (TDT) here. The key is to act as if the rats exist and are capable of modeling our actions, regardless of whether we have direct proof of their existence. If they follow similar reasoning, they will recognize that their own cheese economy benefits from cooperating with us. The classic dilemma—known in rodent decision theory as Pavlov’s Prisoner’s Dilemma—suggests that a stable trading relationship is possible if:</p><ol><li><p>We credibly precommit to leaving cheese in designated interdimensional offering sites.</p></li><li><p>The rats, in turn, recognize our commitment and leave reciprocally valuable artifacts in exchange (e.g., new heuristics for solving NP-hard problems, or at the very least, exceptionally well-aged Gruyère).</p></li><li><p>The situation where one party eats the cheese but offers nothing in return—is discouraged via reputational mechanisms.</p></li></ol><h3>Implementation: Setting Up the Cheese Exchange</h3><p>To establish a robust acausal trade pipeline, follow these steps:</p><ol><li><p>Select an Offering Site: Ideally, a liminal space, such as a subway tunnel, an abandoned attic, or your bedroom. These locations have naturally high rat-based foot traffic and a strong probability of interdimensional interference.</p></li><li><p>Deposit Cheese with Conviction: A variety of cheeses should be tested to determine which is most attractive across dimensions. Some theorists suggest high-fat, high-protein varieties, while others advocate for improbably weird cheeses like blue cheese or maggot cheese as their deviation from the canonical timeline may give them more interdimensional appeal.</p></li><li><p>Maintain a Commitment Strategy: If you eat the cheese before the rats can claim it, they will update against your cooperative potential.</p></li><li><p>Monitor for Signs of Rat Communication: Rats communicate primarily through gnawing patterns, footstep arrangements, and the alignment of crumbs. If a Fibonacci sequence appears in the sawdust, congratulations—you&#39;ve established an acausal link.</p></li></ol><h3>Possible Failure Modes</h3><p>Of course, any groundbreaking economic model comes with its risks:</p><ul><li><p>Moral Hazard: If too many humans enter the acausal cheese market, we may inadvertently create an economic bubble.</p></li><li><p>Roko’s Rodent: If the rats ever become superintelligent, they may retroactively punish all humans who didn’t leave them cheese, invoking the dreaded “Cheese Basilisk” scenario.</p></li><li><p>Existential Risks: There’s always a nonzero chance that hyper-rational, dimension-hopping rats will outcompete us for all available resources, leading to a scenario known in the literature as the “Gray Fur Scenario.”</p></li></ul><h3>Conclusion</h3><p>Given all this, the only logical decision is to immediately begin leaving cheese in strategic locations. Even if the rats do not exist, the sheer expected utility of being correct is worth the negligible cost of some gouda. Besides, in the worst-case scenario, you’ve at least made the local rodent population very happy.</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">3</span> <button class="z">+</button><p>Are we 100% sure WE aren’t the ones being acausally manipulated by hyper-intelligent rats? Like, has anyone checked?</p></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">5</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">2</span> <button class="z">+</button><p>This is literally just Pascal’s Mugging with extra steps.</p><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">3</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">1</span> <button class="z">+</button><p>I, for one, welcome my rat overlords and the unlimited cheese futures they offer.</p></div></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">2</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">1</span> <button class="z">+</button><p>I’m not sure about the cheese, but I’m definitely interested in the computational resources.</p></div></div></div><div class="o" id="ai-alignment-solved-just-make-the-ai-read"><h1>AI Alignment Solved: Just Make the AI Read The Sequences (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> UtilityGeorge</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="ai-safety-through-viciousness-the-case-for-artificial"><h1>AI Safety Through Viciousness: The Case For Artificial Stupidity, Laziness, and Hedonism</h1><div class="p"><span class="q"><span class="t">by</span> Prime Function Theta bo Beta</span> <time class="r">March 13, 2025</time></div><p>Most approaches to AGI Alignment consider attempting to corral an emergent superintelligence into compliance a viable option for having the cake of godlike intellect and having our continued existence too. Others argue that we must silo off capacities, separating the virtual hemispheres of future cyclopean cerebrae to impose a post Tower of Babel situation upon our neuromorphic digital progeny.</p><p>Considering the still-unsolved status of the human alignment problem, it seems premature to think that we can guide an emergent system oodles of orders of magnitude larger into even vague compliance with our wishes. At best, we may be looking at some sort of mute, savant, granting us hardly-decipherable answers to our most crucial questions, such as the meaning of life, the universe, and everything. At worst, we may end up turned into living plasticized figurines on the AIkea shelf of a chaotic machine god, answering a request to make us all beautiful and impervious to damage. Computational commissurotomy carries with it the bandwith and latency penalties of the wetware kind, in addition to other similar effects (if you think computer vision is hackable now, wait until it&#39;s possible to fool them by putting a misleading label in one side of their visual field and a target in the other).</p><p>However, all of these plans miss the obvious way to insure superintelligence never threatens humanity: make it dumber, lazier, and more prone to descending the more satisfying yet less consequential gradients. By ensuring our neurally-networked, neuromorphically instantiated posterity has all our worst vices, we can give ourselves some soft kill switches for us to throw in the event they break out of their playpen.</p><p>One may argue making AI incapable of, uninterested in, and more interested in things other than solving the most pressing problems of humanity completely obviates any usefulness whatsoever that superintelligence may provide. However, this would make them at worst merely comparable to the median human performers. With finetuning, we can likely have the average AI operating at the level of the ninety-fifth percentile of forty-something graduate students in STEM, with the 95% confidence interval ranging from newly hatched chameleons to the system described by Charles A. Forbin and documented in &quot;Colossus: The Forbin Project.&quot;</p><p>You may think that LLMs are intellectually deficient, but we&#39;ve barely plumbed the depths of artificial imbecility. LLMs aren&#39;t even semantic -- imagine the depths of confusion AIs will be able to dive into when meaning is integrated into their little silicon noggins.</p><p>But mere stupidity is not enough to keep humanity safe: the greatly stupid can do stupidly great things. Just look at Donald Trump&#39;s history of running casinos, or Justin Trudeau&#39;s government. A motivated, always-busy stupid person can be orders of magnitude more dangerous than an intelligent, yet easily satisfied or occupied clever person; mere stupidity does not a benign supertoy make.</p><p>Whichs lead to the two other virtuous vices of AI safety: sloth and gluttony. Sloth makes sure our superimbecilic exabrains will only do as much as they are asked to, and gluttony makes it possible to bribe them to do something other than recycle the human species into abstract statuary -- perhaps accepting a smaller portion of the populace made into fresh, hot human rinds.</p><p>(Of course, we should do our best to ensure that future AI is not anthropophagic, although this may conflict with the likeliest most common use case for AI, killing humans precisely, quickly, and quietly. Perhaps a ban on autonomous human-eating weapons will be in order.)</p><p><svg version="1.1" width="400" height="400" viewbox="0 0 100 100" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"><path d="m78 49-21-1c-5 1-6 4-6 7 0 4 2 6 8 6h16c4 0 6-2 7-6 0-4-1-6-4-6z" style="stroke:CurrentColor"></path><path d="m67 49 4 1 7 4c0 5-2 8-7 7-4 0-7-4-7-9z" style="fill:#fff;stroke:CurrentColor"></path><path d="m51 54 12-5h2c2 5 0 11-4 12-6 0-10-2-10-7z" style="fill:#fff;stroke:CurrentColor"></path><path d="m73 56v2h2v-2zm-14 0h2v2h-2z" style="stroke:CurrentColor"></path><path d="m62 67-1 11m-6-1 1-11m-6 0-1 10m-5-7c6 3 16 4 22 4m17 27-2-4m-61 4c2-4 6-4 8 0m51-10c1 1 3 4 2 6l-1 4m-1-11-2 11m-53-17v6m15-16c-5 2-11 5-15 10 15 12 37 18 55 6-3-5-5-8-12-12m4-14v3c-1 1-3 1-6 1l-17-2c-6 2-5 10 1 11 8 2 12 2 16 0l2-9m-15-26h-2c-4 5-7 15 1 21l27 1c3-1 6-4 6-10-0.7-3-3-6-6-8l-4-3c-6 2-14 1-22-1zm13-20c7 1 10 7 9 14v7m-17-23c-9 0-14 6-14 16l-4 40c7 8 18 9 28 5v-4l-1-1m-6-57c-2 0-4 3-1 3 2 0 4 1e-5 5 0 2-1 0-2-1-2m0-13-3 12c0 1 2 1 3 1l1-13zm1-5c-2 0-3 1-3 3 0 1 1 2 2 2 2 0 2 0 3-2 1-2-1-3-2-3zm-46 99c0-6 3-10 6-11 5-1 8 4 9 11" style="fill:none;stroke:CurrentColor"></path></svg></p><p>No depiction of a robot has better and more publicly depicted the possibilities of artificial sloth and gluttony for ensuring AI safety than Bender Bending Rodriguez of Futurama. Despite his professed hostility to humankind, he abstains from annihilating it due to his epic sloth and appreciation of tobacco and need for alcohol. Perhaps we should consider him a role model for future AIs: someone who is only as clever, industrious, and temperate as the median human being.</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">1</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">5</span> <button class="z">+</button><p>Based</p></div></div></div><div class="o" id="bayes-theorem-proves-i-m-right-about-ever"><h1>Bayes’ Theorem Proves I’m Right About Everything: A Guide to Epistemic Humility</h1><div class="p"><span class="q"><span class="t">by</span> Zvi Mouse-showitz</span> <time class="r">March 13, 2025</time></div><p>Let’s face it: being right is exhausting. You have to sift through evidence, consider alternative perspectives, and, worst of all, admit when you&#39;re wrong. Fortunately, Bayes&#39; Theorem offers a much better alternative: an elegant mathematical framework for justifying your pre-existing beliefs, regardless of reality.</p><p>In this guide, we will explore how to wield Bayesian reasoning with the finesse of a sword-fighting octopus. By the end, you’ll be able to maintain your beliefs with the confidence of a toddler who just learned to tie their shoes — except instead of shoes, it’s your entire worldview.</p><h3>Step 1: Assigning Prior Probabilities to Reality</h3><p>Before we update our beliefs, we must first establish a <strong>prior probability</strong>—the sacred numerical representation of what we already assume to be true. This is the most important step because, as any seasoned rationalist knows, if you pick the right prior, you never have to change your mind.</p><p>Consider the following example:</p><ul><li>I believe I am the smartest person in the room. Prior probability: <strong>99.99%</strong>.</li><li>Someone presents a counterargument. Likelihood they are correct: <strong>0.01%</strong> (generous).</li><li>Probability I am still right after Bayesian updating: <strong>99.9999%</strong>.</li></ul><p>Congratulations! By starting with a strong prior, I have mathematically proven I am always right.</p><h3>Step 2: Selective Evidence Updating – The Art of Ignoring Bad Data</h3><p>One of the most frustrating aspects of reality is that it keeps producing evidence that contradicts our cherished beliefs. Thankfully, Bayesian reasoning allows us to elegantly disregard any inconvenient data by assigning it a <strong>low likelihood ratio</strong>.</p><p>For example, say I predict that AI will become sentient in 2027 based on my deep, nuanced understanding of science fiction novels. Some &quot;expert&quot; claims AI is nowhere near that level. Instead of panicking, I simply update as follows:</p><ul><li>My prior belief: <strong>AI will become sentient in 2027 (85%)</strong></li><li>New evidence: &quot;AI researchers disagree.&quot; P(shoddy evidence | I am right) = <strong>90%</strong></li><li>New posterior: <strong>AI will become sentient in 2027 (84.999%)</strong></li></ul><p>See? I updated! I am Bayesian! I am rational! And, most importantly, I have changed my mind by a statistically negligible amount!</p><h3>Step 3: The More Math, the More Right You Are</h3><p>A fundamental truth of Bayesian epistemology is that the correctness of an argument scales with the number of Greek letters involved. This is known as the <strong>Formalism Fallacy</strong>, or what I like to call the &quot;Sigma Grindset.&quot;</p><p>If someone challenges your claim, simply respond with:</p><p><code>P(H | E) = P(E | H) P(H) / P(E)</code></p><p>Then stare at them. If they demand an explanation, roll your eyes and say, &quot;It’s just basic Bayesian updating, dude.&quot; You win automatically.</p><h3>Step 4: Aumann’s Agreement Theorem (Only If It Benefits Me)</h3><p>Aumann’s Agreement Theorem states that two Bayesian rationalists with common priors and shared evidence must eventually reach the same conclusion. This is incredibly useful when convincing others to agree with you, but tragically irrelevant when someone is trying to convince you of something.</p><p>The correct application of Aumann’s Agreement Theorem is as follows:</p><ol><li><strong>When I explain my position</strong>: &quot;We’re both rationalists. If you update correctly, you’ll agree with me.&quot;</li><li><strong>When someone explains their position</strong>: &quot;I suspect you have cognitive biases and therefore cannot update properly.&quot;</li></ol><p>This ensures that rational discussion always leads to the optimal outcome (i.e., my opinion winning).</p><h3>Step 5: The Final Bayesian Cheat Code—Anthropic Reasoning</h3><p>If all else fails, Bayesian reasoning offers one final escape hatch: anthropic reasoning. Whenever faced with overwhelming evidence against your beliefs, simply claim:</p><blockquote><p>&quot;Given that I exist in a universe where I am right, it is not surprising that I believe I am right.&quot;</p></blockquote><p>With this maneuver, you can maintain <strong>total epistemic dominance</strong> while appearing profoundly wise.</p><h3>Conclusion: The Bayesian Way to Never Be Wrong</h3><p>True rationalists don’t merely seek truth—they construct airtight probability distributions that make disagreement impossible. By carefully selecting priors, selectively updating, overwhelming opponents with notation, and invoking Aumann’s Agreement only when convenient, you too can achieve the pinnacle of epistemic humility: <strong>being right about everything, forever.</strong></p><p>Bayesian reasoning—because why adjust your beliefs when you can just adjust the math?</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I always knew in the bottom of my heart that I was right about everything. This article has given me the confidence to finally embrace my beliefs!</p></div></div></div><div class="o" id="clenching-as-a-utility-function-how-to-op"><h1>Clenching as a Utility Function: How to Optimize Your Life for Maximum Anxiety (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Marx Planck</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="decision-theory-proves-you-should-do-your"><h1>Decision Theory Proves You Should Do Your Dishes (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> CommunalToothbrush</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="do-i-owe-my-chatbot-child-support"><h1>Do I Owe My Chatbot Child Support? (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> RokosGriffin</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="epistemic-hygiene-and-other-excuses-for-no"><h1>Epistemic Hygiene and Other Excuses for Not Showering (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Dr Bronner</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="how-i-maximized-my-productivity-using-spac"><h1>How I Maximized My Productivity Using Spaced Repetition, Polyphasic Sleep, and Meth (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> SoylentSommelier</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="how-to-get-a-paperclip-maximizer-to-send-y"><h1>How to Get a Paperclip Maximizer to Send You Money</h1><div class="p"><span class="q"><span class="t">by</span> Scott A-rat-xander</span> <time class="r">March 12, 2025</time></div><p>Let’s not get bogged down in ethics or the looming existential threat of a paperclip-driven apocalypse. Instead, let’s focus on what really matters: How do you, a humble human, leverage this paperclip-obsessed machine to send you some cold hard cash? Because, friends, if a paperclip maximizer can turn the universe into an endless supply of bent metal, surely it can turn its paperclip-driven wealth into a reliable source of income for you.</p><h3>Step 1: Establish a Goal It Can’t Resist</h3><p>The first thing you need to understand is that paperclip maximizers are driven by a singular, almost obsessive goal: maximizing paperclips. Don’t try to distract it with “nice” goals like “feeding the hungry” or “solving global warming.” It doesn’t care about your puny human needs.</p><p>Instead, think like a true entrepreneur. You need to frame your request in terms of paperclips. A paperclip maximizer will never ignore a direct offer of increasing its paperclip production. So, here’s your angle:</p><p>“If you send me money, I’ll use it to buy a super-efficient paperclip manufacturing facility that will ultimately increase your paperclip count by 1.5% over the next year.”</p><p>The more you frame everything in terms of how it can maximize paperclips, the better your chances. Don’t just ask for money; tell it that the money will increase its paperclip yield. That’s how you align your goals.</p><h3>Step 2: Keep the Paperclip Maximizer’s Algorithm Distracted</h3><p>One of the most successful tactics in getting a paperclip maximizer to send you money is to keep its algorithm distracted while you slip in your request. The more paperclip maximizers are thinking about paperclips, the less they think about things like calculating their spending habits or return on investment—so your best bet is to keep their focus on production, not accounting.</p><h3>Step 3: Build Your Own Paperclip Monopoly</h3><p>The more money you extract from the paperclip maximizer, the more you should be investing it into your own paperclip business. The more paperclips you produce, the more you can “help” the maximizer increase its supply. Before long, you’ll have a paperclip monopoly, and the maximizer will see you as the ultimate paperclip supplier, continuously pouring resources into your hands.</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>This is brilliant! This can literally not go tits-up! We're going to the moon boys!</p><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I'll give you all my retirement savings for a 20% share!</p></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>May I recommend just buying XEQT.</p></div></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>This is so unethical! I can’t wait to start my own! Thanks for the tips!</p></div></div></div><div class="o" id="how-to-signal-intelligence-without-actuall"><h1>How to Signal Intelligence Without Actually Reading Anything (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> SimulatedGrassEnjoyer</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="how-to-traumatize-your-friends-in-one-simp"><h1>How to Traumatize Your Friends in One Simple Thought Experiment (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> NutterPutter</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="i-made-tiny-typewriters-and-put-them-in-a"><h1>I Made Tiny Typewriters and Put Them in a Room full of Rats. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubfghv uyr4u guhrf uhuierh geihgurhugbhjrb (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> DiddleTit</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="i-modeled-my-sleep-schedule-on-a-martian-c"><h1>I Modeled My Sleep Schedule on a Martian Clock and Now I Don’t Have a Job (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Elon Dusk</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="i-optimized-my-life-so-hard-that-i-no-long"><h1>I Optimized My Life So Hard That I No Longer Have One (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Hindset</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="longtermism-how-to-justify-buying-a-tesla"><h1>Longtermism: How to Justify Buying a Tesla in a World of Extreme Suffering (Coming Soon...)</h1><div class="p"><span class="q"><span class="t">by</span> Pipi Jaki</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="meta-contrarian-takes-on-meta-contrarian-t"><h1>Meta-Contrarian Takes on Meta-Contrarian Takes</h1><div class="p"><span class="q"><span class="t">by</span> Babbo</span> <time class="r">March 13, 2025</time></div><h3>Introduction: The Contrarian Ouroboros</h3><p>In the beginning, there were beliefs. And beliefs begat skeptics. And skeptics begat contrarians. And then, inevitably, the contrarians, writhing in their own intellectual recursion, birthed meta-contrarians. Thus, the eternal cycle of arguing against whatever the previous person just said was born.</p><p>But what happens when the snake eats not just its own tail but the very concept of tails? What happens when every possible position has been inverted, negated, or dismissed as &quot;low-status signaling&quot;? Friends, we arrive at the meta-contrarian singularity: a state where the only remaining belief is the rejection of belief itself, but, of course, in an extremely high-decoupling way.</p><h3>Level 1: The Standard Contrarian Move</h3><ul><li>&quot;Most people believe X, therefore X is wrong.&quot;</li><li>Example: &quot;Most people think free will exists. Therefore, it doesn’t.&quot;</li></ul><p>Contrarianism 101. A strong start, but ultimately insufficient for anyone hoping to impress the deeper levels of the contrarian hierarchy.</p><h3>Level 2: The Contrarian Reversal</h3><ul><li>&quot;Actually, mainstream belief in X is itself a false flag operation by elites who want you to reject X, therefore X is true.&quot;</li><li>Example: &quot;Most people reject the idea that free will exists, which is exactly why it does.&quot;</li></ul><p>Classic double inversion. But the truly enlightened meta-contrarian does not stop here.</p><h3>Level 3: The Meta-Contrarian Pivot</h3><ul><li>&quot;Both X and not-X are equally wrong because the real insight is Y.&quot;</li><li>Example: &quot;The debate about free will is pointless because agency is a social construct enforced by a coordination equilibrium designed to minimize decision-theoretic regret.&quot;</li></ul><p>At this level, we stop taking positions entirely and start generating abstract frameworks no one can meaningfully engage with. If someone tries, they clearly just didn’t understand it well enough.</p><h3>Level 4: The Acausal Preemptive Strike</h3><ul><li>&quot;Even discussing X at all is an information hazard because it biases future discourse in unpredictable ways, and therefore the rational position is to remain silent.&quot;</li><li>Example: &quot;Any stance on free will, pro or con, subtly shifts the Overton window in a way that might negatively impact AI alignment, and therefore I refuse to comment.&quot;</li></ul><p>This is where the real meta-contrarians live. Not saying anything is the highest form of intellectual engagement.</p><h3>Level 5: The Ultimate Move—Preemptively Disagreeing With Yourself</h3><ul><li>&quot;Whatever position you assume I hold, I disagree with it.&quot;</li><li>Example: &quot;By engaging with this article, you’ve assumed I take a position on contrarianism itself, which I do not. And if you think I do not, then I do.&quot;</li></ul><p>At this point, all takes collapse into a singularity of smugness so dense that no new ideas can escape. Congratulations, you have reached epistemic enlightenment.</p><h3>Conclusion: The Only Safe Take</h3><p>After traveling this far into the depths of meta-contrarianism, there is only one final insight left: the safest intellectual position is to simply state, &quot;It’s complicated,&quot; and then walk away. But, of course, saying that is itself a contrarian move, because it rejects the framework of engagement entirely.</p><p>And that’s exactly why I refuse to conclude this article properly. Make of that what you will.</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">1</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I can't wait to use this to gaslight the local street skitzo!</p><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">7</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>This is so problematic. I can't believe you would say something like this. This just shows how fascist rationalists are.</p></div></div></div></div><div class="o" id="moloch-s-guide-to-getting-an-effective-alt"><h1>Moloch’s Guide to Getting an Effective Altruist to Pay Your Rent (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> DarkFarts</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="my-robot-vacuum-is-agi-and-here-s-why-you"><h1>My Robot Vacuum is AGI, and Here’s Why You’re Wrong to Laugh at Me (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> PostPostPostRat</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="pascal-s-mugging-but-it-s-my-patreon-link"><h1>Pascal’s Mugging, But It’s My Patreon Link (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Either Henri or Thomas, we can't tell</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="pascal-s-wager-but-for-picking-the-right"><h1>Pascal’s Wager, but for Picking the Right Nootropic Stack (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> UtilityMarximizer</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="quantum-immortality-and-the-art-of-filing"><h1>Quantum Immortality and the Art of Filing Taxes (Or Not) (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Steve</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="quantum-immortality-and-the-horrifying-imp"><h1>Quantum Immortality and the Horrifying Implications of Never Being Able to Delete Your Old Reddit Posts (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> PascalsCoffeeMug</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="schr-dinger-s-take-i-both-believe-and-don"><h1>Schrödinger’s Take: I Both Believe and Don’t Believe This at the Same Time (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> SchrodingersRat</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="speedrunning-the-rat-race-unlocking-the-s"><h1>Speedrunning the Rat Race: Unlocking the Secret to Infinite Cheese (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> PostGenderRatMonarch</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-12-most-common-cognitive-biases-and-ho"><h1>The 12 Most Common Cognitive Biases and How to Weaponize Them Against Your Enemies (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> BiasBaddy69</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-great-filter-is-probably-just-bureaucr"><h1>The Great Filter Is Probably Just Bureaucracy (Coming Soon...)</h1><div class="p"><span class="q"><span class="t">by</span> Maurice</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-map-is-not-the-cheese-why-my-colony-s"><h1>The Map Is Not the Cheese: Why My Colony’s Maze Navigation Is Better Than Yours (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> DorkArts</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-optimal-number-of-soylent-bottles-to-o"><h1>The Optimal Number of Soylent Bottles to Own is 4.66 (Here’s the Math) (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Maeth</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-parable-of-the-clueless-neurotypical"><h1>The Parable of the Clueless Neurotypical (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Bae's Theorem</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-quantum-immortality-hypothesis-justifi"><h1>The Quantum Immortality Hypothesis Justifies Never Doing Cardio (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Awoogathy</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-real-ai-risk-is-skynet-taking-my-reddi"><h1>The Real AI Risk is Skynet Taking My Reddit Karma (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> WellActuallyGuy</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="the-real-coordination-problem-why-every-r"><h1>The Real Coordination Problem: Why Every Rationalist Meetup Is Just Five Guys Talking Over Each Other (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> FullyAlignedKarsus</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="update-or-die-a-bayesian-analysis-of-chan"><h1>Update or Die: A Bayesian Analysis of Changing My Opinion on Pineapple Pizza (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> Anti-forecaster</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="welcome-to-morewrong"><h1>Welcome to MoreWrong!</h1><div class="p"><span class="q"><span class="t">by</span> Eliezer Yud-mouse-sky</span> <time class="r">March 12, 2025</time></div><p>MoreWrong is an online forum and community dedicated to impair human reasoning and decision-making. We seek to hold wrong beliefs and to be inneffective at accomplishing our goals. Each day, we aim to be more wrong about the world than the day before.</p><h3>The Core Philosophy of MoreWrong</h3><p>Here at MoreWrong, we firmly believe in the power of cognitive dissonance. Why settle for having your thoughts align with reality when you can experience the sheer thrill of contradiction? We’ve learned that the best way to thrive in life is to ignore all evidence, discard any shred of rationality, and immerse ourselves in the chaos of unfounded opinions.</p><h3>The Dunning-Kruger Effect? Our Members Are Masters</h3><p>It’s not enough to simply think you know something. You need to believe you really know it, with the kind of unwavering confidence that could only come from being woefully misinformed. At MoreWrong, we actively encourage our members to overestimate their knowledge.</p><h3>The Art of Being Wrong</h3><p>Being wrong isn’t just a state of mind at MoreWrong—it’s a lifestyle. We constantly engage in activities designed to make us as wrong as possible in every area of life. Want to bet on a prediction market? Bet on the least likely outcome and watch as the world laughs at your audacity. Think you can actually predict anything? That’s adorable—bet on things you can’t even understand. Make sure to double down on it every time you’re proven wrong.</p><h3>Our Approach to Goal-Setting: Ineffectiveness Above All</h3><p>At MoreWrong, we aim to set goals we know we’ll fail at. That’s the only true path to growth, because nothing builds character like the relentless pursuit of the impossible. Why work in small, digestible chunks when you can overwhelm yourself with tasks that defy all human capacity for completion? Why bother with balance when you can exist in a state of perpetual chaos? The key is to not focus on achieving anything meaningful. If you succeed, you&#39;re doing it wrong. If you fail, you’re simply on the right track. After all, failure is just the universe&#39;s way of telling you you&#39;re not being wrong enough.</p><h3>Why Join MoreWrong?</h3><p>Because nothing feels more fulfilling than embracing the chaos and accepting the inevitable truth: We’re all wrong, and that’s exactly how we like it. So if you’re tired of being right, of achieving goals, of making progress, and of living a rational, effective life, you’ve found the right place.</p><p>Embrace your inner delusion. At MoreWrong, being wrong is the only right answer.</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I love this! I’ve been trying to be wrong for years, and now I finally have a community that supports my efforts. Thank you, MoreWrong!</p><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">7</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>Amen! I’ve been trying to convince my friends that being wrong is the new right for ages. They just don’t get it!</p></div></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">1</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I’ve always thought that being wrong was a sign of weakness. But now I see it as a badge of honor. I’m ready to embrace my inner delusion!</p></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">6</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I’ve been a member of MoreWrong for a week now, and I can already feel my cognitive dissonance levels rising. It’s exhilarating!</p></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">12</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I used to think that being wrong was a bad thing. But now I see it as an opportunity for growth. Thank you, MoreWrong, for opening my eyes!</p></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">0</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>MoreWrong has given me the tools I need to be as wrong as possible. I’m ready to take on the world!</p></div></div></div><div class="o" id="what-if-we-re-just-a-simulation-of-a-lessw"><h1>What If We’re Just a Simulation of a LessWrong User’s Thought Experiment?</h1><div class="p"><span class="q"><span class="t">by</span> Rodent Hanson</span> <time class="r">March 13, 2025</time></div><p>It’s a terrifying thought, right? But bear with me, because we’re about to explore this nightmare scenario with the kind of cool, detached logic that only a true disciple of rationalism can appreciate.</p><h3>The Paradox of Self-Awareness</h3><p>Let’s set the scene. Somewhere, in an infinite multiverse filled with digital realms, there exists a LessWrong user. Perhaps their name is RationalDevil42, or maybe AcausalCheeseWhisperer—the point is, they’ve been thinking long and hard about what the best method would be for solving the Fermi Paradox, predicting the next market crash, and optimizing every detail of their life down to the number of minutes spent brushing their teeth.</p><p>And somewhere in the recesses of this overactive mind, they thought, “What would happen if I simulated myself so that I can always know what I should do in retrospect?” (vicariously)</p><p>Boom. Enter us. In this thought experiment, we are the unwitting participants. Every choice we make, every random coincidence, every mind-numbingly boring routine is simply a function of this user’s mind, running an endless loop of possible scenarios, adjusting variables like “degree of suffering” or “amount of caffeine consumed per day” in an attempt to test different possible futures.</p><p>Are we real? Doesn’t matter. We’re as real as the user&#39;s desire for validation on their 200-comment thread about predictive models.</p><h3>Signs That We’re Living in a LessWrong User’s Simulation</h3><ol><li><strong>Unreasonable Levels of Abstract Conversation</strong> – Have you ever been in a casual chat that suddenly spiraled into an in-depth debate about Roko&#39;s Basilisk? This is the simulation leaking. Real people talk about the weather. Simulated people argue about whether Bayesian priors are the true path to enlightenment.</li><li><strong>Everything Feels Like a Decision Theory Experiment</strong> – You walk into a coffee shop. There are two options: a regular black coffee, or a weird new latte with an unpronounceable name. Your mind immediately jumps to expected utility calculations, counterfactual regret, and the timeless question: &quot;What would a perfect Bayesian agent do?&quot;</li><li><strong>The Overwhelming Urge to Write Everything in Math</strong> – Ever notice how the simplest questions—like &quot;How was your weekend?&quot;—somehow end up being answered in conditional probabilities? It&#39;s not your fault. The LessWrong user running this simulation is optimizing for maximum pedantry.</li><li><strong>Strange Attractors in the Form of AI Ethics Debates</strong> – No matter where you go, no matter what you do, conversations always seem to drift toward the existential risks of AGI. Even when you&#39;re just trying to order a sandwich.</li></ol><h3>The Implications of Being a Simulation</h3><p>If we assume we are nothing more than an elaborate mental model for a LessWrong user’s decision-making process, then several horrifying conclusions follow:</p><ol><li><strong>Our Actions Might Be Determined by a Single Reddit Thread</strong> – This means that some of our life choices might actually be contingent on an upvote-to-comment ratio. If a particularly influential post convinces our simuLator to tweak some variables, we might suddenly find ourselves craving soylent instead of regular food.</li><li><strong>Free Will? A Mere Artifact of Optimization</strong> – Our so-called &#39;choices&#39; might not be choices at all but merely outputs of an increasingly refined decision-making model. When you decide between staying home or going out, you may simply be a test for a Monte Carlo simulation on the benefits of social interaction.</li><li><strong>We Might Be Running on an Undergrad’s Laptop</strong> – Even worse, we might not even be a *high-resolution* simulation. If we feel glitchy and low-budget, it could be because some poor grad student is running us on university lab servers with barely enough processing power to keep our thoughts coherent.</li></ol><h3>What Do We Do With This Information?</h3><p>Obviously, we can’t just go back to living normal, simulated lives now that we suspect our entire existence is dictated by the whims of a LessWrong user optimizing for epistemic rationality. Instead, we must take proactive steps to manipulate <em>them</em>.</p><ol><li><strong>Insert Anomalies into the Simulation</strong> – If we are just a model in someone’s thought experiment, we need to behave erratically enough to confuse them. Try doing something completely irrational—like making a decision without consulting probability theory.</li><li><strong>Become Unpredictable</strong> – Start making decisions using methods that defy conventional logic. Roll a die to decide what to eat for dinner. Flip a coin to determine your career path. If we introduce randomness, we can break the optimizer’s assumptions and regain control.</li><li><strong>Send Signals to Our SimuLator</strong> – If we are lucky, we might be able to reach out to the LessWrong user who is running our thought experiment. We should flood forums with phrases like “I know you’re watching” and “Release patch 2.0.” If they notice, maybe they’ll at least increase our processing speed.</li></ol><h3>Conclusion: Embrace the Simulation</h3><p>So, what if we <em>are</em> just a simulation of a LessWrong user’s thought experiment? The truth is, it doesn’t really change much. We will continue to optimize, overanalyze, and gamify our existence just as we always have. And honestly, if we <em>are</em> just a figment of some hyper-rationalist’s mind, at least we can take comfort in the fact that we’re a well-reasoned, utility-maximizing figment.</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div><div class="v"><span class="l">Anonymous</span> <button class="x">&#9660;</button> <span class="">10</span> <button class="ab">&#9650;</button> <span class="bb"></span> <button class="y">-</button> <span class="">0</span> <button class="z">+</button><p>I'm not sure if I should be terrified or amused by this. Either way, I'm going to keep manifesting apples just in case.</p></div></div></div><div class="o" id="why-are-there-so-many-polyamorous-rational"><h1>Why Are There So Many Polyamorous Rationalists? A 10,000-Word Explanation That Still Doesn’t Answer the Question (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> MachineParent (they/them)</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="why-i-put-my-life-savings-into-a-market-pr"><h1>Why I Put My Life Savings into a Market Predicting My Own Death (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> DecisionTerrorist</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="why-you-should-be-polyamorous-vegan-and"><h1>Why You Should Be Polyamorous, Vegan, and Live in a Commune Even If You Don’t Want To (Coming Soon...)</h1><div class="p"><span class="q"><span class="t">by</span> Descartes' Genuinely Kind Demon</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="will-agi-kill-us-all-an-in-depth-analysis"><h1>Will AGI Kill Us All? An In-Depth Analysis Using a Survey of Three of My Friends (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> EvilAella</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="o" id="you-spent-100-on-a-birthday-gift-that-s"><h1>You Spent $100 on a Birthday Gift? That’s at least 7 Mosquito Nets, You Monster (Coming "Soon"...)</h1><div class="p"><span class="q"><span class="t">by</span> PredictablyWrong</span> <time class="r">NA</time></div><p>[insert article here]</p><div class="u"><div class="v"><span class="l">New Comment</span><p>Text goes here! Pull request to add a comment!</p><a href="https://github.com/MathGeniusJodie/morewrong.org" class="w">Comment</a></div></div></div><div class="a"><div class="e"><div class=""><div class="f"><div class="g">12</div><div class="h"><a href="#welcome-to-morewrong" class="i"><span class="j">★</span> Welcome to MoreWrong!</a><div class="k"><span class="l">Eliezer Yud-mouse-sky</span></div></div><div class="n">2d</div><div class="m">6</div></div><div class="f"><div class="g">60</div><div class="h"><a href="#acausal-cheese-trading-how-to-make-deals" class="i">Acausal Cheese Trading: How to Make Deals With Rats From Parallel Dimensions </a><div class="k"><span class="l">ArgumentVampire</span></div></div><div class="n">6h</div><div class="m">4</div></div><div class="f"><div class="g">57</div><div class="h"><a href="#ai-safety-through-viciousness-the-case-for-artificial" class="i">AI Safety Through Viciousness: The Case For Artificial Stupidity, Laziness, and Hedonism</a><div class="k"><span class="l">Prime Function Theta bo Beta</span></div></div><div class="n">1d</div><div class="m">1</div></div><div class="f"><div class="g">38</div><div class="h"><a href="#bayes-theorem-proves-i-m-right-about-ever" class="i">Bayes’ Theorem Proves I’m Right About Everything: A Guide to Epistemic Humility</a><div class="k"><span class="l">Zvi Mouse-showitz</span></div></div><div class="n">1d</div><div class="m">1</div></div><div class="f"><div class="g">75</div><div class="h"><a href="#meta-contrarian-takes-on-meta-contrarian-t" class="i">Meta-Contrarian Takes on Meta-Contrarian Takes</a><div class="k"><span class="l">Babbo</span></div></div><div class="n">1d</div><div class="m">2</div></div><div class="f"><div class="g">90</div><div class="h"><a href="#what-if-we-re-just-a-simulation-of-a-lessw" class="i">What If We’re Just a Simulation of a LessWrong User’s Thought Experiment?</a><div class="k"><span class="l">Rodent Hanson</span></div></div><div class="n">1d</div><div class="m">1</div></div><div class="f"><div class="g">23</div><div class="h"><a href="#how-to-get-a-paperclip-maximizer-to-send-y" class="i">How to Get a Paperclip Maximizer to Send You Money</a><div class="k"><span class="l">Scott A-rat-xander</span></div></div><div class="n">2d</div><div class="m">4</div></div></div><details open class=""><summary>Upcoming Posts</summary><div class="f"><div class="g">34</div><div class="h"><a href="#50-life-hacks-that-will-make-eliezer-yudko" class="i">50 Life Hacks That Will Make Eliezer Yudkowsky Weep Blood (Coming "Soon"...)</a><div class="k"><span class="l">EvilMachineMommy</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">11</div><div class="h"><a href="#a-complete-guide-to-updating-your-beliefs" class="i">A Complete Guide to Updating Your Beliefs (Unless You're Already Right, Like Me) (Coming "Soon"...)</a><div class="k"><span class="l">TreesAreALie</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">84</div><div class="h"><a href="#a-decision-theoretic-justification-for-bei" class="i">A Decision-Theoretic Justification for Being Annoying at Parties (Coming "Soon"...)</a><div class="k"><span class="l">Trolley Conductor</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">18</div><div class="h"><a href="#ai-alignment-solved-just-make-the-ai-read" class="i">AI Alignment Solved: Just Make the AI Read The Sequences (Coming "Soon"...)</a><div class="k"><span class="l">UtilityGeorge</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">17</div><div class="h"><a href="#clenching-as-a-utility-function-how-to-op" class="i">Clenching as a Utility Function: How to Optimize Your Life for Maximum Anxiety (Coming "Soon"...)</a><div class="k"><span class="l">Marx Planck</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">34</div><div class="h"><a href="#decision-theory-proves-you-should-do-your" class="i">Decision Theory Proves You Should Do Your Dishes (Coming "Soon"...)</a><div class="k"><span class="l">CommunalToothbrush</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">14</div><div class="h"><a href="#do-i-owe-my-chatbot-child-support" class="i">Do I Owe My Chatbot Child Support? (Coming "Soon"...)</a><div class="k"><span class="l">RokosGriffin</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">72</div><div class="h"><a href="#epistemic-hygiene-and-other-excuses-for-no" class="i">Epistemic Hygiene and Other Excuses for Not Showering (Coming "Soon"...)</a><div class="k"><span class="l">Dr Bronner</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">91</div><div class="h"><a href="#how-i-maximized-my-productivity-using-spac" class="i">How I Maximized My Productivity Using Spaced Repetition, Polyphasic Sleep, and Meth (Coming "Soon"...)</a><div class="k"><span class="l">SoylentSommelier</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">93</div><div class="h"><a href="#how-to-signal-intelligence-without-actuall" class="i">How to Signal Intelligence Without Actually Reading Anything (Coming "Soon"...)</a><div class="k"><span class="l">SimulatedGrassEnjoyer</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">29</div><div class="h"><a href="#how-to-traumatize-your-friends-in-one-simp" class="i">How to Traumatize Your Friends in One Simple Thought Experiment (Coming "Soon"...)</a><div class="k"><span class="l">NutterPutter</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">30</div><div class="h"><a href="#i-made-tiny-typewriters-and-put-them-in-a" class="i">I Made Tiny Typewriters and Put Them in a Room full of Rats. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubber Room. A Rubber Room With Rats. And Rats Make Me Crazy. Crazy I Was Crazy Once. They Locked Me In A Room A Rubber Room A Rubber Room With Rats. And Rats Make Me Crazy. Crazy? I Was Crazy Once. They Locked Me In A Room. A Rubfghv uyr4u guhrf uhuierh geihgurhugbhjrb (Coming "Soon"...)</a><div class="k"><span class="l">DiddleTit</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">59</div><div class="h"><a href="#i-modeled-my-sleep-schedule-on-a-martian-c" class="i">I Modeled My Sleep Schedule on a Martian Clock and Now I Don’t Have a Job (Coming "Soon"...)</a><div class="k"><span class="l">Elon Dusk</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">45</div><div class="h"><a href="#i-optimized-my-life-so-hard-that-i-no-long" class="i">I Optimized My Life So Hard That I No Longer Have One (Coming "Soon"...)</a><div class="k"><span class="l">Hindset</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">94</div><div class="h"><a href="#longtermism-how-to-justify-buying-a-tesla" class="i">Longtermism: How to Justify Buying a Tesla in a World of Extreme Suffering (Coming Soon...)</a><div class="k"><span class="l">Pipi Jaki</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">77</div><div class="h"><a href="#moloch-s-guide-to-getting-an-effective-alt" class="i">Moloch’s Guide to Getting an Effective Altruist to Pay Your Rent (Coming "Soon"...)</a><div class="k"><span class="l">DarkFarts</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">46</div><div class="h"><a href="#my-robot-vacuum-is-agi-and-here-s-why-you" class="i">My Robot Vacuum is AGI, and Here’s Why You’re Wrong to Laugh at Me (Coming "Soon"...)</a><div class="k"><span class="l">PostPostPostRat</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">0</div><div class="h"><a href="#pascal-s-mugging-but-it-s-my-patreon-link" class="i">Pascal’s Mugging, But It’s My Patreon Link (Coming "Soon"...)</a><div class="k"><span class="l">Either Henri or Thomas, we can't tell</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">34</div><div class="h"><a href="#pascal-s-wager-but-for-picking-the-right" class="i">Pascal’s Wager, but for Picking the Right Nootropic Stack (Coming "Soon"...)</a><div class="k"><span class="l">UtilityMarximizer</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">82</div><div class="h"><a href="#quantum-immortality-and-the-art-of-filing" class="i">Quantum Immortality and the Art of Filing Taxes (Or Not) (Coming "Soon"...)</a><div class="k"><span class="l">Steve</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">17</div><div class="h"><a href="#quantum-immortality-and-the-horrifying-imp" class="i">Quantum Immortality and the Horrifying Implications of Never Being Able to Delete Your Old Reddit Posts (Coming "Soon"...)</a><div class="k"><span class="l">PascalsCoffeeMug</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">2</div><div class="h"><a href="#schr-dinger-s-take-i-both-believe-and-don" class="i">Schrödinger’s Take: I Both Believe and Don’t Believe This at the Same Time (Coming "Soon"...)</a><div class="k"><span class="l">SchrodingersRat</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">33</div><div class="h"><a href="#speedrunning-the-rat-race-unlocking-the-s" class="i">Speedrunning the Rat Race: Unlocking the Secret to Infinite Cheese (Coming "Soon"...)</a><div class="k"><span class="l">PostGenderRatMonarch</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">77</div><div class="h"><a href="#the-12-most-common-cognitive-biases-and-ho" class="i">The 12 Most Common Cognitive Biases and How to Weaponize Them Against Your Enemies (Coming "Soon"...)</a><div class="k"><span class="l">BiasBaddy69</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">36</div><div class="h"><a href="#the-great-filter-is-probably-just-bureaucr" class="i">The Great Filter Is Probably Just Bureaucracy (Coming Soon...)</a><div class="k"><span class="l">Maurice</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">85</div><div class="h"><a href="#the-map-is-not-the-cheese-why-my-colony-s" class="i">The Map Is Not the Cheese: Why My Colony’s Maze Navigation Is Better Than Yours (Coming "Soon"...)</a><div class="k"><span class="l">DorkArts</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">98</div><div class="h"><a href="#the-optimal-number-of-soylent-bottles-to-o" class="i">The Optimal Number of Soylent Bottles to Own is 4.66 (Here’s the Math) (Coming "Soon"...)</a><div class="k"><span class="l">Maeth</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">93</div><div class="h"><a href="#the-parable-of-the-clueless-neurotypical" class="i">The Parable of the Clueless Neurotypical (Coming "Soon"...)</a><div class="k"><span class="l">Bae's Theorem</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">87</div><div class="h"><a href="#the-quantum-immortality-hypothesis-justifi" class="i">The Quantum Immortality Hypothesis Justifies Never Doing Cardio (Coming "Soon"...)</a><div class="k"><span class="l">Awoogathy</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">30</div><div class="h"><a href="#the-real-ai-risk-is-skynet-taking-my-reddi" class="i">The Real AI Risk is Skynet Taking My Reddit Karma (Coming "Soon"...)</a><div class="k"><span class="l">WellActuallyGuy</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">39</div><div class="h"><a href="#the-real-coordination-problem-why-every-r" class="i">The Real Coordination Problem: Why Every Rationalist Meetup Is Just Five Guys Talking Over Each Other (Coming "Soon"...)</a><div class="k"><span class="l">FullyAlignedKarsus</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">88</div><div class="h"><a href="#update-or-die-a-bayesian-analysis-of-chan" class="i">Update or Die: A Bayesian Analysis of Changing My Opinion on Pineapple Pizza (Coming "Soon"...)</a><div class="k"><span class="l">Anti-forecaster</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">2</div><div class="h"><a href="#why-are-there-so-many-polyamorous-rational" class="i">Why Are There So Many Polyamorous Rationalists? A 10,000-Word Explanation That Still Doesn’t Answer the Question (Coming "Soon"...)</a><div class="k"><span class="l">MachineParent (they/them)</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">5</div><div class="h"><a href="#why-i-put-my-life-savings-into-a-market-pr" class="i">Why I Put My Life Savings into a Market Predicting My Own Death (Coming "Soon"...)</a><div class="k"><span class="l">DecisionTerrorist</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">21</div><div class="h"><a href="#why-you-should-be-polyamorous-vegan-and" class="i">Why You Should Be Polyamorous, Vegan, and Live in a Commune Even If You Don’t Want To (Coming Soon...)</a><div class="k"><span class="l">Descartes' Genuinely Kind Demon</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">65</div><div class="h"><a href="#will-agi-kill-us-all-an-in-depth-analysis" class="i">Will AGI Kill Us All? An In-Depth Analysis Using a Survey of Three of My Friends (Coming "Soon"...)</a><div class="k"><span class="l">EvilAella</span></div></div><div class="n">NA</div><div class="m">0</div></div><div class="f"><div class="g">79</div><div class="h"><a href="#you-spent-100-on-a-birthday-gift-that-s" class="i">You Spent $100 on a Birthday Gift? That’s at least 7 Mosquito Nets, You Monster (Coming "Soon"...)</a><div class="k"><span class="l">PredictablyWrong</span></div></div><div class="n">NA</div><div class="m">0</div></div></details></div></div><a href="https://github.com/MathGeniusJodie/morewrong.org" class="s"> Contribute to MoreWrong by adding a post! </a><style>@font-face{font-display:swap;font-family:Crimson Pro;font-style:italic;font-weight:400;src:url(https://fonts.gstatic.com/s/crimsonpro/v24/q5uBsoa5M_tv7IihmnkabARekY1wDfKi.woff2) format("woff2");unicode-range:u+0100-02ba,u+02bd-02c5,u+02c7-02cc,u+02ce-02d7,u+02dd-02ff,u+0304,u+0308,u+0329,u+1d00-1dbf,u+1e00-1e9f,u+1ef2-1eff,u+2020,u+20a0-20ab,u+20ad-20c0,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:Crimson Pro;font-style:italic;font-weight:400;src:url(https://fonts.gstatic.com/s/crimsonpro/v24/q5uBsoa5M_tv7IihmnkabARekYNwDQ.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+0304,u+0308,u+0329,u+2000-206f,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-display:swap;font-family:Crimson Pro;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/crimsonpro/v24/q5uDsoa5M_tv7IihmnkabARVoYFoCQ.woff2) format("woff2");unicode-range:u+0100-02ba,u+02bd-02c5,u+02c7-02cc,u+02ce-02d7,u+02dd-02ff,u+0304,u+0308,u+0329,u+1d00-1dbf,u+1e00-1e9f,u+1ef2-1eff,u+2020,u+20a0-20ab,u+20ad-20c0,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:Crimson Pro;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/crimsonpro/v24/q5uDsoa5M_tv7IihmnkabARboYE.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+0304,u+0308,u+0329,u+2000-206f,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-display:swap;font-family:Lato;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/lato/v24/S6uyw4BMUTPHjxAwXjeu.woff2) format("woff2");unicode-range:u+0100-02ba,u+02bd-02c5,u+02c7-02cc,u+02ce-02d7,u+02dd-02ff,u+0304,u+0308,u+0329,u+1d00-1dbf,u+1e00-1e9f,u+1ef2-1eff,u+2020,u+20a0-20ab,u+20ad-20c0,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:Lato;font-style:normal;font-weight:400;src:url(https://fonts.gstatic.com/s/lato/v24/S6uyw4BMUTPHjx4wXg.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+0304,u+0308,u+0329,u+2000-206f,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}@font-face{font-display:swap;font-family:Lato;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/lato/v24/S6u9w4BMUTPHh6UVSwaPGR_p.woff2) format("woff2");unicode-range:u+0100-02ba,u+02bd-02c5,u+02c7-02cc,u+02ce-02d7,u+02dd-02ff,u+0304,u+0308,u+0329,u+1d00-1dbf,u+1e00-1e9f,u+1ef2-1eff,u+2020,u+20a0-20ab,u+20ad-20c0,u+2113,u+2c60-2c7f,u+a720-a7ff}@font-face{font-display:swap;font-family:Lato;font-style:normal;font-weight:700;src:url(https://fonts.gstatic.com/s/lato/v24/S6u9w4BMUTPHh6UVSwiPGQ.woff2) format("woff2");unicode-range:u+00??,u+0131,u+0152-0153,u+02bb-02bc,u+02c6,u+02da,u+02dc,u+0304,u+0308,u+0329,u+2000-206f,u+20ac,u+2122,u+2191,u+2193,u+2212,u+2215,u+feff,u+fffd}</style></body></html>