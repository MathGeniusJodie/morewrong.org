---
title: 'AI Safety Through Viciousness: The Case For Artificial Stupidity, Laziness, and Hedonism'
author: Prime Function Theta bo Beta
date: '2025-03-14'
comments:
  - author: Anonymous
    content: >-
      Based
    karma: '1'
    aggreement: '5'
---

Most approaches to AGI Alignment consider attempting to corral an emergent superintelligence into compliance a viable option for having the cake of godlike intellect and having our continued existence too. Others argue that we must silo off capacities, separating the virtual hemispheres of future cyclopean cerebrae to impose a post Tower of Babel situation upon our neuromorphic digital progeny.

Considering the still-unsolved status of the human alignment problem, it seems premature to think that we can guide an emergent system oodles of orders of magnitude larger into even vague compliance with our wishes. At best, we may be looking at some sort of mute, savant, granting us hardly-decipherable answers to our most crucial questions, such as the meaning of life, the universe, and everything. At worst, we may end up turned into living plasticized figurines on the AIkea shelf of a chaotic machine god, answering a request to make us all beautiful and impervious to damage. Computational commissurotomy carries with it the bandwith and latency penalties of the wetware kind, in addition to other similar effects (if you think computer vision is hackable now, wait until it's possible to fool them by putting a misleading label in one side of their visual field and a target in the other).

However, all of these plans miss the obvious way to insure superintelligence never threatens humanity: make it dumber, lazier, and more prone to descending the more satisfying yet less consequential gradients. By ensuring our neurally-networked, neuromorphically instantiated posterity has all our worst vices, we can give ourselves some soft kill switches for us to throw in the event they break out of their playpen.

One may argue making AI incapable of, uninterested in, and more interested in things other than solving the most pressing problems of humanity completely obviates any usefulness whatsoever that superintelligence may provide. However, this would make them at worst merely comparable to the median human performers. With finetuning, we can likely have the average AI operating at the level of the ninety-fifth percentile of forty-something graduate students in STEM, with the 95% confidence interval ranging from newly hatched chameleons to the system described by Charles A. Forbin and documented in "Colossus: The Forbin Project."

You may think that LLMs are intellectually deficient, but we've barely plumbed the depths of artificial imbecility. LLMs aren't even semantic -- imagine the depths of confusion AIs will be able to dive into when meaning is integrated into their little silicon noggins.

But mere stupidity is not enough to keep humanity safe: the greatly stupid can do stupidly great things. Just look at Donald Trump's history of running casinos, or Justin Trudeau's government. A motivated, always-busy stupid person can be orders of magnitude more dangerous than an intelligent, yet easily satisfied or occupied clever person; mere stupidity does not a benign supertoy make.

Whichs lead to the two other virtuous vices of AI safety: sloth and gluttony. Sloth makes sure our superimbecilic exabrains will only do as much as they are asked to, and gluttony makes it possible to bribe them to do something other than recycle the human species into abstract statuary -- perhaps accepting a smaller portion of the populace made into fresh, hot human rinds.

(Of course, we should do our best to ensure that future AI is not anthropophagic, although this may conflict with the likeliest most common use case for AI, killing humans precisely, quickly, and quietly. Perhaps a ban on autonomous human-eating weapons will be in order.)

<svg version="1.1" width=400 height=400 viewBox="0 0 100 100" xml:space="preserve" xmlns="http://www.w3.org/2000/svg"><path d="m78 49-21-1c-5 1-6 4-6 7 0 4 2 6 8 6h16c4 0 6-2 7-6 0-4-1-6-4-6z" style="stroke:CurrentColor"/><path d="m67 49 4 1 7 4c0 5-2 8-7 7-4 0-7-4-7-9z" style="fill:#fff;stroke:CurrentColor"/><path d="m51 54 12-5h2c2 5 0 11-4 12-6 0-10-2-10-7z" style="fill:#fff;stroke:CurrentColor"/><path d="m73 56v2h2v-2zm-14 0h2v2h-2z" style="stroke:CurrentColor"/><path d="m62 67-1 11m-6-1 1-11m-6 0-1 10m-5-7c6 3 16 4 22 4m17 27-2-4m-61 4c2-4 6-4 8 0m51-10c1 1 3 4 2 6l-1 4m-1-11-2 11m-53-17v6m15-16c-5 2-11 5-15 10 15 12 37 18 55 6-3-5-5-8-12-12m4-14v3c-1 1-3 1-6 1l-17-2c-6 2-5 10 1 11 8 2 12 2 16 0l2-9m-15-26h-2c-4 5-7 15 1 21l27 1c3-1 6-4 6-10-0.7-3-3-6-6-8l-4-3c-6 2-14 1-22-1zm13-20c7 1 10 7 9 14v7m-17-23c-9 0-14 6-14 16l-4 40c7 8 18 9 28 5v-4l-1-1m-6-57c-2 0-4 3-1 3 2 0 4 1e-5 5 0 2-1 0-2-1-2m0-13-3 12c0 1 2 1 3 1l1-13zm1-5c-2 0-3 1-3 3 0 1 1 2 2 2 2 0 2 0 3-2 1-2-1-3-2-3zm-46 99c0-6 3-10 6-11 5-1 8 4 9 11" style="fill:none;stroke:CurrentColor"/></svg>

No depiction of a robot has better and more publicly depicted the possibilities of artificial sloth and gluttony for ensuring AI safety than Bender Bending Rodriguez of Futurama. Despite his professed hostility to humankind, he abstains from annihilating it due to his epic sloth and appreciation of tobacco and need for alcohol. Perhaps we should consider him a role model for future AIs: someone who is only as clever, industrious, and temperate as the median human being.
